{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move to studying constrained optimization problems i.e., the full problem\n",
    "$$\n",
    "\\begin{align} \\\n",
    "\\min \\quad &f(x)\\\\\n",
    "\\text{s.t.} \\quad & g_j(x) \\geq 0\\text{ for all }j=1,\\ldots,J\\\\\n",
    "& h_k(x) = 0\\text{ for all }k=1,\\ldots,K\\\\\n",
    "&a_i\\leq x_i\\leq b_i\\text{ for all } i=1,\\ldots,n\\\\\n",
    "&x\\in \\mathbb R^n,\n",
    "\\end{align}\n",
    "$$\n",
    "where for all $i=1,\\ldots,n$ it holds that $a_i,b_i\\in \\mathbb R$ or they may also be $-\\infty$ of $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## On optimal solutions for constrained problems\n",
    "* Two types of constraints: equality and inequality constraints\n",
    "* Inequality constraint $g_i$ is said to be *active* if $g_i(x)=0$\n",
    "* Linear constraints are much easier to consider --> their gradients are constant\n",
    "* Nonlinear constraints trickier --> gradient changes for different values of decision variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No constraints\n",
    "![](images/unconstrained.png)\n",
    "<span style=\"font-size: 10pt;\">*Adopted from Prof. L.T. Biegler (Carnegie Mellon University)*</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inequality constraints\n",
    "![](images/inequality_constraints.jpg)\n",
    "<span style=\"font-size: 10pt;\">*Adopted from Prof. L.T. Biegler (Carnegie Mellon University)*</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Both equality and equality constraints\n",
    "![](images/constraints.jpg)\n",
    "<span style=\"font-size: 10pt;\">*Adopted from Prof. L.T. Biegler (Carnegie Mellon University)*</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Transforming the constraints\n",
    "Inequality to equality:\n",
    "$$\n",
    "g_i(x)\\leq0 \\iff g_i(x)+y_i^2=0\n",
    "$$\n",
    "* $y_i$ is a *slack variable*; constraint is active if $y_i=0$\n",
    "* By adding $y_i^2$ no need to add $y_i\\geq0$\n",
    "* If $g$ is linear, linearity can be preserved by $g_i(x)+y_i=0, y_i\\geq0$\n",
    "\n",
    "Type of inequality:\n",
    "$$\n",
    "g_i(x)\\geq0 \\iff -g_i(x)\\leq0\n",
    "$$\n",
    "\n",
    "Equality to inequality:\n",
    "$$\n",
    "h_i(x)=0 \\iff h_i(x)\\geq0 \\text{ & } -h_i(x) \\geq0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example problem\n",
    "For example, we can have an optimization problem\n",
    "$$\n",
    "\\begin{align} \\\n",
    "\\min \\quad &x_1^2+x_2^2\\\\\n",
    "\\text{s.t.} \\quad & x_1+x_2-1\\geq 0\\\\\n",
    "&-1\\leq x_1\\leq 1, x_2\\leq 3.\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to optimize that problem, we can define the following python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f_constrained(x):\n",
    "    return np.linalg.norm(x)**2,[x[0]+x[1]-1],[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f is 1.0\n",
      "The values of inequality constraints are:\n",
      "0, \n"
     ]
    }
   ],
   "source": [
    "(f_val,ieq,eq) = f_constrained([1,0])\n",
    "print(\"Value of f is \"+str(f_val))\n",
    "if len(ieq)>0:\n",
    "    print(\"The values of inequality constraints are:\")\n",
    "    for ieq_j in ieq:\n",
    "        print(str(ieq_j)+\", \")\n",
    "if len(eq)>0:\n",
    "    print(\"The values of the equality constraints are:\")\n",
    "    for eq_k in eq:\n",
    "        print(str(eq_k)+\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is this solution feasible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution is feasible\n"
     ]
    }
   ],
   "source": [
    "if all([ieq_j>=0 for ieq_j in ieq]) and all([eq_k==0 for eq_k in eq]):\n",
    "    print(\"Solution is feasible\")\n",
    "else:\n",
    "    print(\"Solution is infeasible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indirect and direct methods for constrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two categories of methods for constrained optimization: Indirect and direct methods. The main difference is that\n",
    "1. Indirect methods convert the constrained optimization problem into a single or a sequence of unconstrained optimization problems, that are then solved. Often, the intermediate solutions do not need to be feasible, but the sequence of solutions converges to a solution that is optimal (and, thus, feasible).\n",
    "2. Direct methods deal with the constrained optimization problem directly. In this case, the intermediate solutions are feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indirect methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Penalty function methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IDEA:** Include constraints into the objective function with the help of penalty functions that penalize constraint violations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let, $\\alpha(x):\\mathbb R^n\\to\\mathbb R$ be a function so that \n",
    "* $\\alpha(x)= 0$, for all feasible $x$\n",
    "* $\\alpha(x)>0$, for all infeasible $x$.\n",
    "\n",
    "Define optimization problems\n",
    "$$\n",
    "\\begin{align} \\\n",
    "\\min \\qquad &f(x)+r\\alpha(x)\\\\\n",
    "\\text{s.t.} \\qquad &x\\in \\mathbb R^n\n",
    "\\end{align}\n",
    "$$\n",
    "for $r>0$. Let $x_r$ be the optimal solutions of these problems.\n",
    "\n",
    "In this case, the optimal solutions $x_r$ converge to the optimal solution of the constrained problem, when $r\\to\\infty$, if such a solution exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, good ideas for penalty functions are\n",
    "* $h_k(x)^2$ for equality constraints,\n",
    "* $\\left(\\min\\{0,g_j(x)\\}\\right)^2$ for inequality constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Illustrative example\n",
    "$$\n",
    "\\min x \\text{ s.t. } -x + 2 \\leq 0\n",
    "$$\n",
    "Let\n",
    "$$\n",
    "\\alpha(x) = \\{(\\max[0,(-x+2)])^2, 0 \\text{ if }x\\geq2\\}\n",
    "$$\n",
    "Then \n",
    "$$\n",
    "\\alpha(x) = (-x+2)^2, \\text{ if } x<2\n",
    "$$\n",
    "Minimum of $f+r\\alpha(x)$ is at $2-1/2r$\n",
    "![](images/penalty.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def alpha(x,f):\n",
    "    (_,ieq,eq) = f(x)\n",
    "    return sum([min([0,ieq_j])**2 for ieq_j in ieq])+sum([eq_k**2 for eq_k in eq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha([1,0],f_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def penalized_function(x,f,r):\n",
    "    return f(x)[0] + r*alpha(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40001.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalized_function([-1,0],f_constrained,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.333333\n",
      "         Iterations: 42\n",
      "         Function evaluations: 68\n",
      "[0.33330469 0.33330859]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "res = minimize(lambda x:penalized_function(x,f_constrained,1),\n",
    "               [0,0],method='Nelder-Mead', \n",
    "         options={'disp': True})\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f is 0.2221866333770754\n",
      "The values of inequality constraints are:\n",
      "-0.3333867187499997, \n",
      "Solution is infeasible\n"
     ]
    }
   ],
   "source": [
    "(f_val,ieq,eq) = f_constrained(res.x)\n",
    "print(\"Value of f is \"+str(f_val))\n",
    "if len(ieq)>0:\n",
    "    print(\"The values of inequality constraints are:\")\n",
    "    for ieq_j in ieq:\n",
    "        print(str(ieq_j)+\", \")\n",
    "if len(eq)>0:\n",
    "    print(\"The values of the equality constraints are:\")\n",
    "    for eq_k in eq:\n",
    "        print(str(eq_k)+\", \")\n",
    "\n",
    "if all([ieq_j>=0 for ieq_j in ieq]) and all([eq_k==0 for eq_k in eq]):\n",
    "    print(\"Solution is feasible\")\n",
    "else:\n",
    "    print(\"Solution is infeasible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to set the penalty term $r$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penalty term should\n",
    "* be large enough in order for the solutions be close enough to the feasible region, but\n",
    "* not be too large to\n",
    "  * cause numerical problems, or\n",
    "  * cause premature convergence to non-optimal solutions because of relative tolerances.\n",
    "\n",
    "Usually, the penalty term is either\n",
    "* set as big as possible without causing problems (hard to know), or\n",
    "* updated iteratively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Barrier function methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IDEA:** Prevent leaving the feasible region so that the value of the objective is $\\infty$ outside the feasible set.\n",
    "\n",
    "This method is only applicable to problems with inequality constraints and for which the set \n",
    "$$\\{x\\in \\mathbb R^n: g_j(x)>0\\text{ for all }j=1,\\ldots,J\\}$$\n",
    "is non-empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta:\\{x\\in \\mathbb R^n: g_j(x)>0\\text{ for all }j=1,\\ldots,J\\}\\to \\mathbb R$ be a function so that $\\beta(x)\\to \\infty$, when $x\\to\\partial\\{x\\in \\mathbb R^n: g_j(x)>0\\text{ for all }j=1,\\ldots,J\\}$, where $\\partial A$ is the boundary of the set $A$. Now, define optimization problem \n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\qquad & f(x) + r\\beta(x)\\\\\n",
    "\\text{s.t. } \\qquad & x\\in \\{x\\in \\mathbb R^n: g_j(x)>0\\text{ for all }j=1,\\ldots,J\\}.\n",
    "\\end{align}\n",
    "$$\n",
    "and let $x_r$ be the optimal solution of this problem (which we assume to exist for all $r>0$).\n",
    "\n",
    "In this case, $x_r$ converges to the optimal solution of the problem (if it exists), when $r\\to 0^+$ (i.e., $r$ converges to zero from the right)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A good idea for barrier function is $\\frac1{g_j(x)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(x,f):\n",
    "    _,ieq,_ = f(x)\n",
    "    try:\n",
    "        value=sum([1/max([0,ieq_j]) for ieq_j in ieq])\n",
    "    except ZeroDivisionError:\n",
    "        value = float(\"inf\")\n",
    "    return value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def function_with_barrier(x,f,r):\n",
    "    return f(x)[0]+r*beta(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.176342\n",
      "         Iterations: 31\n",
      "         Function evaluations: 58\n",
      "[0.63976739 0.63976021]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "res = minimize(lambda x:function_with_barrier(x,f_constrained,0.1),\n",
    "               [1,1],method='Nelder-Mead', options={'disp': True})\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f is 0.818595435883283\n",
      "The values of inequality constraints are:\n",
      "0.2795275970900519, \n",
      "Solution is feasible\n"
     ]
    }
   ],
   "source": [
    "(f_val,ieq,eq) = f_constrained(res.x)\n",
    "print(\"Value of f is \"+str(f_val))\n",
    "if len(ieq)>0:\n",
    "    print(\"The values of inequality constraints are:\")\n",
    "    for ieq_j in ieq:\n",
    "        print(str(ieq_j)+\", \")\n",
    "if len(eq)>0:\n",
    "    print(\"The values of the equality constraints are:\")\n",
    "    for eq_k in eq:\n",
    "        print(str(eq_k)+\", \")\n",
    "if all([ieq_j>=0 for ieq_j in ieq]) and all([eq_k==0 for eq_k in eq]):\n",
    "    print(\"Solution is feasible\")\n",
    "else:\n",
    "    print(\"Solution is infeasible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other notes about using penalty and barrier function methods\n",
    "\n",
    "* It is worthwile to consider whether feasibility can be compromized. If the constraints do not have any tolerances, then barrier function method should be considered.\n",
    "* Also barrier methods parameter can be set iteratively\n",
    "* Penalty and barrier functions should be chosen so that they are differentiable (thus $x^2$ above)\n",
    "* In both methods, the minimum is attained at the limit.\n",
    "* Different penalty and barrier parameters can be used for differnt constraints, even for same problem."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
