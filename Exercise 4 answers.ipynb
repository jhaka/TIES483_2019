{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_constrained(x):\n",
    "    return x[0]**2+x[1]**2+x[0]+2*x[1], [], [x[0]+x[1]-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(x,f):\n",
    "    (_,ieq,eq) = f(x)\n",
    "    return sum([min([0,ieq_j])**2 for ieq_j in ieq])\\\n",
    "+sum([eq_k**2 for eq_k in eq])\n",
    "\n",
    "def penalized_function(x,f,r):\n",
    "    return f(x)[0] + r*alpha(x,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us solve the penalized problem with penalty term growin in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74340989 0.24336301] 95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "r = 1\n",
    "x_old = np.array([float('inf')]*2)\n",
    "x_new = [0,0]\n",
    "while np.linalg.norm(x_new-x_old)>0.0001:\n",
    "    res = minimize(lambda x:penalized_function(x,f_constrained,r),\n",
    "               [0,0],method='Nelder-Mead')\n",
    "    x_old = x_new\n",
    "    x_new = np.array(res.x)\n",
    "    r = r+1\n",
    "print(x_new, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_constrained_approx(x,epsilon):\n",
    "    return x[0]**2+x[1]**2+x[0]+2*x[1], [x[0]+x[1]-1+epsilon,\\\n",
    "                                         epsilon-(x[0]+x[1]-1)], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(x,f):\n",
    "    _,ieq,_ = f(x)\n",
    "    try:\n",
    "        value=sum([1/max([0,ieq_j]) for ieq_j in ieq])\n",
    "    except ZeroDivisionError:\n",
    "        value = float(\"inf\")\n",
    "    return value\n",
    "def function_with_barrier(x,f,r):\n",
    "    return f(x)[0]+r*beta(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7496876 0.2496876] 0.05 0.5\n",
      "[0.74992188 0.24992188] 0.025 0.25\n",
      "[0.74998047 0.24998047] 0.0125 0.125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ad\n",
    "from scipy.optimize import minimize\n",
    "r = 1.0\n",
    "epsilon = .1\n",
    "x_old = np.array([float('inf')]*2)\n",
    "x_new = [1,0]\n",
    "while np.linalg.norm(x_new-x_old)>0.0001:\n",
    "    g = lambda x: function_with_barrier(x,\\\n",
    "               lambda y: f_constrained_approx(y,epsilon),r)\n",
    "    res = minimize(g,x_new,method='Newton-CG',jac=ad.gh(g)[0],\\\n",
    "                   hess=ad.gh(g)[1])\n",
    "    x_old = x_new\n",
    "    x_new = res.x\n",
    "    r=r/2\n",
    "    epsilon = epsilon/2\n",
    "    print(x_new, epsilon, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def project_vector(A,vector):\n",
    "    #convert A into a matrix\n",
    "    A_matrix = np.matrix(A)\n",
    "    #construct the \"first row\" of the matrix [[I,A^T],[A,0]]\n",
    "    left_matrix_first_row = np.concatenate((np.identity(len(vector)),A_matrix.transpose()), axis=1)\n",
    "    #construct the \"second row\" of the matrix\n",
    "    left_matrix_second_row = np.concatenate((A_matrix,np.matrix(np.zeros([len(A),len(A)]))), axis=1)\n",
    "    #combine the whole matrix by combining the rows\n",
    "    left_matrix = np.concatenate((left_matrix_first_row,left_matrix_second_row),axis = 0)\n",
    "    #Solve the system of linear equalities from the previous page\n",
    "    return np.linalg.solve(left_matrix, \\\n",
    "                           np.concatenate((np.matrix(vector).transpose(),\\\n",
    "                                           np.zeros([len(A),1])),axis=0))[:len(vector)]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ad\n",
    "def projected_gradient_method(f,A,start,step,precision):\n",
    "    f_old = float('Inf')\n",
    "    x = np.array(start)\n",
    "    steps = []\n",
    "    f_new = f(x)\n",
    "    while abs(f_old-f_new)>precision:\n",
    "        f_old = f_new\n",
    "        gradient = ad.gh(f)[0](x)\n",
    "        grad_proj = project_vector(A,[-i for i in gradient])#The only changes to steepest..\n",
    "        grad_proj = np.array(grad_proj.transpose())[0] #... descent are here!\n",
    "        x = x+grad_proj*step\n",
    "        f_new = f(x)\n",
    "        steps.append(list(x))\n",
    "    return x,f_new,steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75032652, 0.24967348]),\n",
       " 1.8750002132271604,\n",
       " [[0.9, 0.1],\n",
       "  [0.8400000000000001, 0.15999999999999998],\n",
       "  [0.804, 0.196],\n",
       "  [0.7824, 0.21760000000000002],\n",
       "  [0.76944, 0.23056000000000001],\n",
       "  [0.761664, 0.23833599999999996],\n",
       "  [0.7569984, 0.2430016],\n",
       "  [0.7541990399999999, 0.24580096000000004],\n",
       "  [0.7525194239999999, 0.24748057600000006],\n",
       "  [0.7515116544, 0.24848834560000005],\n",
       "  [0.75090699264, 0.24909300736000006],\n",
       "  [0.750544195584, 0.24945580441600007],\n",
       "  [0.7503265173504, 0.24967348264960007]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_gradient_method(lambda x:f_constrained(x)[0],[[1,1]],[1,0]\\\n",
    "                          ,.2,0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to show that there exists unique Lagrance multiplier vectors $\\lambda^* = (\\lambda^*_1,\\ldots,\\lambda_J^*)$ and $\\mu^*=(\\mu_1^*,\\ldots,\\mu_K^*)$ such that\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\nabla_xL(x,\\lambda,\\mu) = 0\\\\\n",
    "&\\mu_j^*\\geq0,\\text{ for all }j=1,\\ldots,J\\\\\n",
    "&\\mu_j^*g_j(x)=0,\\text{for all }j=1,\\ldots,J,\n",
    "\\end{align}\n",
    "$$\n",
    "where $$L(x,\\lambda,\\mu) = f(x)- \\sum_{k=1}^K\\mu_kg_k(x) -\\sum_{j=1}^J\\lambda_jh_j(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,  $f(x) = x_1^2+x_2^2+x_1+2x_2$, $g(x) = 0$ and $h(x)=x_1+x_2-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, stability rule becomes $$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "2x_1+1-\\lambda = 0\\\\\n",
    "2x_2+2-\\lambda=0.\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have a complementary rule, since we do not have inequality constraints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_KKT_eqc(x,tol):\n",
    "    l = 2*x[0]+1\n",
    "    if abs(2*x[1]+2-l)<=tol:\n",
    "        print(abs(2*x[1]+2-l))\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_KKT_eqc([0.74998093,0.24998093],0.000001)\n",
    "check_KKT_eqc([0.75,0.25],0.000001)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
